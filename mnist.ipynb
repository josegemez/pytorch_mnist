{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch\n",
    "Ejemplo de clasificador con Pytorch, comentado en espa침ol. \n",
    "\n",
    "El cuaderno de Jupyter se ha desarrollado con Visual Code y puedes encontrar el c칩digo en https://github.com/josegemez/pytorch_mnist \n",
    "\n",
    "Se ha desarrollado en python 3.10.4 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import\n",
    "Con las primeras lineas vamos a importar los paquetes que b치sicos de Pytorch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables Generales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size_train = 128\n",
    "batch_size_test = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformaciones "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms=torchvision.transforms.Compose([\n",
    "                            torchvision.transforms.ToTensor(),\n",
    "                            torchvision.transforms.Normalize((0.1307,), (0.3081,))\n",
    "                            ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_mnist = torchvision.datasets.MNIST('/files/', train=True, download=True, transform=transforms)                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.8 * len(dataset_mnist))\n",
    "test_size = len(dataset_mnist) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset_mnist, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_dataset,  batch_size=batch_size_train, shuffle=True,num_workers=0,pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a ver que \"pinta\" tiene cada elemento del cargador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(train_loader)) #asignamos el primer batch a las variables x e y. La variable X contrendra las imagenes e y contrendra las etiquetas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x es un batch, por lo que la primera dimensi칩n coincidira con el batch size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import imshow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "imshow(x[0].view(28,28).numpy()); # transformamos el primer elemento del batch una matriz de numpy y mostramos con matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4, 0, 7, 4, 7, 2, 7, 9, 3, 8, 7, 9, 8, 4, 8, 3, 5, 9, 4, 9, 7, 6, 4, 0,\n",
       "        0, 6, 8, 5, 7, 8, 3, 0, 1, 7, 6, 2, 9, 5, 5, 7, 3, 5, 2, 0, 6, 8, 2, 2,\n",
       "        2, 6, 8, 5, 3, 3, 9, 5, 7, 0, 6, 6, 0, 7, 6, 6, 3, 4, 3, 7, 5, 1, 5, 7,\n",
       "        8, 0, 4, 6, 9, 4, 9, 0, 3, 2, 4, 5, 8, 8, 1, 3, 7, 3, 2, 6, 0, 7, 7, 4,\n",
       "        9, 7, 1, 2, 4, 6, 3, 7, 0, 2, 7, 0, 7, 8, 5, 1, 5, 6, 4, 3, 1, 3, 5, 2,\n",
       "        6, 2, 2, 8, 1, 5, 6, 7])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = torch.utils.data.DataLoader(test_dataset,  batch_size=batch_size_test, shuffle=True, num_workers=0,pin_memory=True)              "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya tenemos los datos preparados, ahora vamos a crear la red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate   =   0.01\n",
    "momentum   =   0.5\n",
    "n_epochs = 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(28*28,40) #capa \"fuly connect\" entrada 28*28 (tama침o de la imagen) 50 neuronas\n",
    "        self.fc1_drop = nn.Dropout(0.2) #dropout (regularizacion) 20% \n",
    "        self.fc2 = nn.Linear(40, 20) #capa fully connect 50 neuronas \n",
    "        self.fc2_drop = nn.Dropout(0.2) #dropout (regularizacion) 20%\n",
    "        self.fc3 = nn.Linear(20, 10) #capa de salida numero de salida igual al de etiquetas\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28) #cambia la forma del tensor, -1 para quitar la dimensiones anteriores y dejarlo todo en una vector de 256 elementos\n",
    "        x = F.relu(self.fc1(x)) #capa fully connect y luego activacion relu\n",
    "        x = self.fc1_drop(x) #dropout (regularizacion)\n",
    "        x = F.relu(self.fc2(x)) #capa fully connect y luego activacion relu\n",
    "        x = self.fc2_drop(x) #dropout (regularizacion)\n",
    "        return F.log_softmax(self.fc3(x), dim=1) #soft max (estimacion estadistica 0-1 de la probabildad de que sea de un etiqueta u otra)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2)) \n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = torch.device('cuda')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net().to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate,\n",
    "                      momentum=momentum)\n",
    "\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.5)\n",
    "criterion =  nn.CrossEntropyLoss().to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (fc1): Linear(in_features=784, out_features=40, bias=True)\n",
       "  (fc1_drop): Dropout(p=0.2, inplace=False)\n",
       "  (fc2): Linear(in_features=40, out_features=20, bias=True)\n",
       "  (fc2_drop): Dropout(p=0.2, inplace=False)\n",
       "  (fc3): Linear(in_features=20, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = []\n",
    "test_loss = []\n",
    "train_acc = []\n",
    "test_acc = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  batch 100 loss: 1.9111501610279082\n",
      "  batch 200 loss: 1.2030225485563277\n",
      "  batch 300 loss: 0.9343264466524124\n",
      "  batch 100 loss: 0.7305975115299225\n",
      "  batch 200 loss: 0.6656734073162078\n",
      "  batch 300 loss: 0.6212339648604392\n",
      "  batch 100 loss: 0.5591327974200249\n",
      "  batch 200 loss: 0.5417657089233399\n",
      "  batch 300 loss: 0.5119213265180588\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epochs):\n",
    "  epoch_train_loss = []\n",
    "  epoch_train_acc = []\n",
    "  epoch_test_loss = []\n",
    "  epoch_test_acc = []\n",
    "  running_loss = 0.\n",
    "  model.train() #modelo en modo entranamiento\n",
    "  for i, datum in enumerate(train_loader):\n",
    "    data, target = datum\n",
    "    data, target = data.to(device=device, non_blocking=True), target.to(device=device, non_blocking=True).long() #se pasan lo datos y las etiquetas al \"device\"\n",
    "    optimizer.zero_grad() #se inicializan los gradientes\n",
    "    output = model(data) #se realiza la predicci칩n propagaci칩n haciea adelante\n",
    "    loss = F.nll_loss(output, target) #se calcula la funcion de perdida entre los valores predichos (output) y los valores reales (target)\n",
    "    pred = output.data.max(1, keepdim=True)[1] #valores predichos\n",
    "    correct = pred.eq(target.data.view_as(pred)).sum()\n",
    "    accuracy = correct.item()/batch_size_train\n",
    "    epoch_train_acc.append(accuracy)\n",
    "    epoch_train_loss.append(loss.cpu().item()) #se guardan el valor de la perdida\n",
    "    loss.backward() #se realiza la retropropagaci칩n \n",
    "    optimizer.step() #se realiza un paso adelante con el learning rate y el gradiente calculado\n",
    "    running_loss += loss.item()\n",
    "    if i % 100 == 99:\n",
    "            last_loss = running_loss / 100 # loss per batch\n",
    "            print('  batch {} loss: {}'.format(i + 1, last_loss))\n",
    "            tb_x = n_epochs * len(train_loader) + i + 1\n",
    "            #tb_writer.add_scalar('Loss/train', last_loss, tb_x)\n",
    "            running_loss = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(n_epochs):\n",
    "  epoch_train_loss = []\n",
    "  epoch_train_acc = []\n",
    "  epoch_test_loss = []\n",
    "  epoch_test_acc = []\n",
    "  running_loss = 0.\n",
    "  model.train() #modelo en modo entranamiento\n",
    "   #perdida de la primera epoca\n",
    "  with tqdm(train_loader, unit='batch') as tepoch: #tqdm para ver la barra de progreso por batch\n",
    "    for data, target in tepoch: #en cada batch data la imagen de 28x28 y target la prediccion\n",
    "      model.train(True)\n",
    "      tepoch.set_description(f'Epoch {epoch}') #texto al final de la barra de progreso\n",
    "      data, target = data.to(device=device, non_blocking=True), target.to(device=device, non_blocking=True).long() #se pasan lo datos y las etiquetas al \"device\"\n",
    "      optimizer.zero_grad() #se inicializan los gradientes\n",
    "      output = model(data) #se realiza la predicci칩n propagaci칩n haciea adelante\n",
    "      loss = F.nll_loss(output, target) #se calcula la funcion de perdida entre los valores predichos (output) y los valores reales (target)\n",
    "      pred = output.data.max(1, keepdim=True)[1] #valores predichos\n",
    "      correct = pred.eq(target.data.view_as(pred)).sum()\n",
    "      accuracy = correct.item()/batch_size_train\n",
    "      epoch_train_acc.append(accuracy)\n",
    "      epoch_train_loss.append(loss.cpu().item()) #se guardan el valor de la perdida\n",
    "      loss.backward() #se realiza la retropropagaci칩n \n",
    "      optimizer.step() #se realiza un paso adelante con el learning rate y el gradiente calculado\n",
    "      running_loss += loss.item()\n",
    "      model.train(False)\n",
    "      i, datum = next(enumerate(test_loader))\n",
    "      data, target = datum\n",
    "      data, target = data.to(device=device, non_blocking=True), target.to(device=device, non_blocking=True).long() #se pasan lo datos y las etiquetas al \"device\"\n",
    "      output = model(data) #se realiza la predicci칩n propagaci칩n haciea adelante\n",
    "      t_loss = F.nll_loss(output, target) #se calcula la funcion de perdida entre los valores predichos (output) y los valores reales (target)    \n",
    "      pred = output.data.max(1, keepdim=True)[1] #valores predichos\n",
    "      correct = pred.eq(target.data.view_as(pred)).sum()    \n",
    "      test_accuracy = correct.item()/batch_size_test\n",
    "      epoch_test_acc.append(test_accuracy)\n",
    "      epoch_test_loss.append(t_loss.cpu().item()) #se guardan el valor de la perdida\n",
    "      train_loss.append(np.mean(epoch_train_loss))\n",
    "      test_loss.append(np.mean(epoch_test_loss))\n",
    "      train_acc.append(np.mean(epoch_train_acc))\n",
    "      test_acc.append(np.mean(epoch_test_acc))\n",
    "      if i % 1000 == 999:\n",
    "        print(f'Lost train {running_loss/1000}')\n",
    "  scheduler.step() #se realiza un paso para cambiar el learning rate\n",
    "  print(f'Epoch {epoch}: Train loss {np.mean(epoch_train_loss)} Test loss {np.mean(epoch_test_loss)} Train accuracy {np.mean(epoch_train_acc)} Test accuracy {np.mean(epoch_test_acc)}')\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def train(model, optimizer, loss_fn, train_dl, val_dl, epochs=20, device='cuda'):\n",
    "    '''\n",
    "    Runs training loop for classification problems. Returns Keras-style\n",
    "    per-epoch history of loss and accuracy over training and validation data.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : nn.Module\n",
    "        Neural network model\n",
    "    optimizer : torch.optim.Optimizer\n",
    "        Search space optimizer (e.g. Adam)\n",
    "    loss_fn :\n",
    "        Loss function (e.g. nn.CrossEntropyLoss())\n",
    "    train_dl : \n",
    "        Iterable dataloader for training data.\n",
    "    val_dl :\n",
    "        Iterable dataloader for validation data.\n",
    "    epochs : int\n",
    "        Number of epochs to run\n",
    "    device : string\n",
    "        Specifies 'cuda' or 'cpu'\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Dictionary\n",
    "        Similar to Keras' fit(), the output dictionary contains per-epoch\n",
    "        history of training loss, training accuracy, validation loss, and\n",
    "        validation accuracy.\n",
    "    '''\n",
    "\n",
    "    print('train() called: model=%s, opt=%s(lr=%f), epochs=%d, device=%s\\n' % \\\n",
    "          (type(model).__name__, type(optimizer).__name__,\n",
    "           optimizer.param_groups[0]['lr'], epochs, device))\n",
    "\n",
    "    history = {} # Collects per-epoch loss and acc like Keras' fit().\n",
    "    history['loss'] = []\n",
    "    history['val_loss'] = []\n",
    "    history['acc'] = []\n",
    "    history['val_acc'] = []\n",
    "\n",
    "    start_time_sec = time.time()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        # --- TRAIN AND EVALUATE ON TRAINING SET -----------------------------\n",
    "        model.train()\n",
    "        train_loss         = 0.0\n",
    "        num_train_correct  = 0\n",
    "        num_train_examples = 0\n",
    "\n",
    "        for batch in train_dl:\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            x    = batch[0].to(device)\n",
    "            y    = batch[1].to(device)\n",
    "            yhat = model(x)\n",
    "            loss = loss_fn(yhat, y)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss         += loss.data.item() * x.size(0)\n",
    "            num_train_correct  += (torch.max(yhat, 1)[1] == y).sum().item()\n",
    "            num_train_examples += x.shape[0]\n",
    "\n",
    "        train_acc   = num_train_correct / num_train_examples\n",
    "        train_loss  = train_loss / len(train_dl.dataset)\n",
    "\n",
    "\n",
    "        # --- EVALUATE ON VALIDATION SET -------------------------------------\n",
    "        model.eval()\n",
    "        val_loss       = 0.0\n",
    "        num_val_correct  = 0\n",
    "        num_val_examples = 0\n",
    "\n",
    "        for batch in val_dl:\n",
    "\n",
    "            x    = batch[0].to(device)\n",
    "            y    = batch[1].to(device)\n",
    "            yhat = model(x)\n",
    "            loss = loss_fn(yhat, y)\n",
    "\n",
    "            val_loss         += loss.data.item() * x.size(0)\n",
    "            num_val_correct  += (torch.max(yhat, 1)[1] == y).sum().item()\n",
    "            num_val_examples += y.shape[0]\n",
    "\n",
    "        val_acc  = num_val_correct / num_val_examples\n",
    "        val_loss = val_loss / len(val_dl.dataset)\n",
    "\n",
    "\n",
    "        print('Epoch %3d/%3d, train loss: %5.2f, train acc: %5.2f, val loss: %5.2f, val acc: %5.2f' % \\\n",
    "              (epoch+1, epochs, train_loss, train_acc, val_loss, val_acc))\n",
    "\n",
    "        history['loss'].append(train_loss)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['acc'].append(train_acc)\n",
    "        history['val_acc'].append(val_acc)\n",
    "\n",
    "    # END OF TRAINING LOOP\n",
    "\n",
    "\n",
    "    end_time_sec       = time.time()\n",
    "    total_time_sec     = end_time_sec - start_time_sec\n",
    "    time_per_epoch_sec = total_time_sec / epochs\n",
    "    print()\n",
    "    print('Time total:     %5.2f sec' % (total_time_sec))\n",
    "    print('Time per epoch: %5.2f sec' % (time_per_epoch_sec))\n",
    "\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train() called: model=Net, opt=SGD(lr=0.010000), epochs=3, device=cuda\n",
      "\n",
      "Epoch   1/  3, train loss:  0.47, train acc:  0.86, val loss:  0.27, val acc:  0.92\n",
      "Epoch   2/  3, train loss:  0.43, train acc:  0.87, val loss:  0.25, val acc:  0.93\n",
      "Epoch   3/  3, train loss:  0.41, train acc:  0.88, val loss:  0.23, val acc:  0.93\n",
      "\n",
      "Time total:     45.93 sec\n",
      "Time per epoch: 15.31 sec\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': [0.470356126387914, 0.4304757753610611, 0.4054767176310221],\n",
       " 'val_loss': [0.273857497215271, 0.2514816032648087, 0.2335377845366796],\n",
       " 'acc': [0.8578541666666667, 0.8706041666666666, 0.8783541666666667],\n",
       " 'val_acc': [0.92125, 0.9275833333333333, 0.93425]}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train(model,optimizer,criterion, train_loader, test_loader, n_epochs, 'cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(epoch_train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(epoch_test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_losses(train_loss, test_loss, save_to_file=None):\n",
    "    fig = plt.figure()\n",
    "    epochs = len(train_loss)\n",
    "    plt.plot(range(epochs), train_loss, 'bo', label='Training loss')\n",
    "    plt.plot(range(epochs), test_loss,  label='Test loss', c=\"red\")\n",
    "    plt.title('Training and test loss')\n",
    "    plt.legend()\n",
    "    plt.ylim([0, 3])\n",
    "    if save_to_file:\n",
    "        fig.savefig()\n",
    "\n",
    "\n",
    "def plot_accuracies(train_acc, test_acc, save_to_file=None):\n",
    "    fig = plt.figure()\n",
    "    epochs = len(train_acc)\n",
    "    plt.plot(range(epochs), train_acc, 'bo', label='Training accuracy')\n",
    "    plt.plot(range(epochs), test_acc,  label='Test accuracy', c=\"red\")\n",
    "    plt.title('Training and test accuracy')\n",
    "    plt.legend()\n",
    "    plt.ylim([0, 1])\n",
    "    if save_to_file:\n",
    "        fig.savefig(save_to_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_losses(train_loss, test_loss, save_to_file=None)\n",
    "plot_accuracies(train_acc, test_acc, save_to_file=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('Pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fda304a6f307d97b29aaae674164dfd82bf6d6216593c67b562cfafd3100d5c6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
