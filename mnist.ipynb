{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch\n",
    "Ejemplo de clasificador con Pytorch, comentado en español. \n",
    "\n",
    "El cuaderno de Jupyter se ha desarrollado con Visual Code y puedes encontrar el código en https://github.com/josegemez/pytorch_mnist \n",
    "\n",
    "Se ha desarrollado en python 3.10.4 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import\n",
    "Con las primeras lineas vamos a importar los paquetes que básicos de Pytorch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables Generales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size_train = 128\n",
    "batch_size_test = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformaciones "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms=torchvision.transforms.Compose([\n",
    "                            torchvision.transforms.ToTensor(),\n",
    "                            torchvision.transforms.Normalize((0.1307,), (0.3081,))\n",
    "                            ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_mnist = torchvision.datasets.MNIST('/files/', train=True, download=True, transform=transforms)                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.8 * len(dataset_mnist))\n",
    "test_size = len(dataset_mnist) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset_mnist, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_dataset,  batch_size=batch_size_train, shuffle=True,num_workers=1,pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a ver que \"pinta\" tiene cada elemento del cargador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(train_loader)) #asignamos el primer batch a las variables x e y. La variable X contrendra las imagenes e y contrendra las etiquetas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x es un batch, por lo que la primera dimensión coincidira con el batch size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import imshow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "imshow(x[0].view(28,28).numpy()); # transformamos el primer elemento del batch una matriz de numpy y mostramos con matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 5, 0, 2, 3, 6, 6, 4, 4, 7, 4, 7, 8, 4, 2, 6, 3, 6, 9, 8, 9, 3,\n",
       "        1, 3, 7, 3, 3, 7, 5, 1, 2, 9, 7, 4, 8, 5, 5, 2, 4, 1, 4, 2, 1, 8, 3, 1,\n",
       "        1, 4, 8, 9, 1, 3, 3, 0, 1, 4, 5, 7, 9, 6, 4, 4, 7, 5, 7, 9, 9, 0, 3, 4,\n",
       "        1, 1, 6, 3, 8, 9, 4, 1, 6, 0, 3, 8, 1, 7, 4, 2, 6, 4, 6, 3, 3, 4, 3, 1,\n",
       "        0, 2, 6, 0, 1, 5, 8, 3, 6, 1, 5, 5, 6, 1, 9, 9, 6, 8, 1, 3, 3, 5, 1, 5,\n",
       "        9, 8, 0, 3, 5, 2, 5, 9])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = torch.utils.data.DataLoader(test_dataset,  batch_size=batch_size_test, shuffle=True, num_workers=1,pin_memory=True)              "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya tenemos los datos preparados, ahora vamos a crear la red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate   =   0.01\n",
    "momentum   =   0.5\n",
    "n_epochs = 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(28*28,40) #capa \"fuly connect\" entrada 28*28 (tamaño de la imagen) 50 neuronas\n",
    "        self.fc1_drop = nn.Dropout(0.2) #dropout (regularizacion) 20% \n",
    "        self.fc2 = nn.Linear(40, 20) #capa fully connect 50 neuronas \n",
    "        self.fc2_drop = nn.Dropout(0.2) #dropout (regularizacion) 20%\n",
    "        self.fc3 = nn.Linear(20, 10) #capa de salida numero de salida igual al de etiquetas\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28) #cambia la forma del tensor, -1 para quitar la dimensiones anteriores y dejarlo todo en una vector de 256 elementos\n",
    "        x = F.relu(self.fc1(x)) #capa fully connect y luego activacion relu\n",
    "        x = self.fc1_drop(x) #dropout (regularizacion)\n",
    "        x = F.relu(self.fc2(x)) #capa fully connect y luego activacion relu\n",
    "        x = self.fc2_drop(x) #dropout (regularizacion)\n",
    "        return F.log_softmax(self.fc3(x), dim=1) #soft max (estimacion estadistica 0-1 de la probabildad de que sea de un etiqueta u otra)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2)) \n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = torch.device('cuda')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net().to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate,\n",
    "                      momentum=momentum)\n",
    "\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.5)\n",
    "criterion =  nn.CrossEntropyLoss().to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (fc1): Linear(in_features=784, out_features=40, bias=True)\n",
       "  (fc1_drop): Dropout(p=0.2, inplace=False)\n",
       "  (fc2): Linear(in_features=40, out_features=20, bias=True)\n",
       "  (fc2_drop): Dropout(p=0.2, inplace=False)\n",
       "  (fc3): Linear(in_features=20, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = []\n",
    "test_loss = []\n",
    "train_acc = []\n",
    "test_acc = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  10%|▉         | 36/375 [01:19<12:54,  2.28s/batch]"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epochs):\n",
    "  epoch_train_loss = []\n",
    "  epoch_train_acc = []\n",
    "  epoch_test_loss = []\n",
    "  epoch_test_acc = []\n",
    "  running_loss = 0.\n",
    "  model.train() #modelo en modo entranamiento\n",
    "   #perdida de la primera epoca\n",
    "  with tqdm(train_loader, unit='batch') as tepoch: #tqdm para ver la barra de progreso por batch\n",
    "    for data, target in tepoch: #en cada batch data la imagen de 28x28 y target la prediccion\n",
    "      model.train()\n",
    "      tepoch.set_description(f'Epoch {epoch}') #texto al final de la barra de progreso\n",
    "      data, target = data.to(device=device, non_blocking=True), target.to(device=device, non_blocking=True).long() #se pasan lo datos y las etiquetas al \"device\"\n",
    "      optimizer.zero_grad() #se inicializan los gradientes\n",
    "      output = model(data) #se realiza la predicción propagación haciea adelante\n",
    "      loss = F.nll_loss(output, target) #se calcula la funcion de perdida entre los valores predichos (output) y los valores reales (target)\n",
    "      pred = output.data.max(1, keepdim=True)[1] #valores predichos\n",
    "      correct = pred.eq(target.data.view_as(pred)).sum()\n",
    "      accuracy = correct.item()/batch_size_train\n",
    "      epoch_train_acc.append(accuracy)\n",
    "      epoch_train_loss.append(loss.cpu().item()) #se guardan el valor de la perdida\n",
    "      loss.backward() #se realiza la retropropagación \n",
    "      optimizer.step() #se realiza un paso adelante con el learning rate y el gradiente calculado\n",
    "      running_loss += loss.item()\n",
    "      i, datum = next(enumerate(test_loader))\n",
    "      data, target = datum\n",
    "      data, target = data.to(device=device, non_blocking=True), target.to(device=device, non_blocking=True).long() #se pasan lo datos y las etiquetas al \"device\"\n",
    "      output = model(data) #se realiza la predicción propagación haciea adelante\n",
    "      t_loss = F.nll_loss(output, target) #se calcula la funcion de perdida entre los valores predichos (output) y los valores reales (target)    \n",
    "      pred = output.data.max(1, keepdim=True)[1] #valores predichos\n",
    "      correct = pred.eq(target.data.view_as(pred)).sum()    \n",
    "      test_accuracy = correct.item()/batch_size_test\n",
    "      epoch_test_acc.append(test_accuracy)\n",
    "      epoch_test_loss.append(t_loss.cpu().item()) #se guardan el valor de la perdida\n",
    "      train_loss.append(np.mean(epoch_train_loss))\n",
    "      test_loss.append(np.mean(epoch_test_loss))\n",
    "      train_acc.append(np.mean(epoch_train_acc))\n",
    "      test_acc.append(np.mean(epoch_test_acc))\n",
    "  scheduler.step() #se realiza un paso para cambiar el learning rate\n",
    "  print(f'Epoch {epoch}: Train loss {np.mean(epoch_train_loss)} Test loss {np.mean(epoch_test_loss)} Train accuracy {np.mean(epoch_train_acc)} Test accuracy {np.mean(epoch_test_acc)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "206.7832682132721"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "running_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(epoch_train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(epoch_test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_losses(train_loss, test_loss, save_to_file=None):\n",
    "    fig = plt.figure()\n",
    "    epochs = len(train_loss)\n",
    "    plt.plot(range(epochs), train_loss, 'bo', label='Training loss')\n",
    "    plt.plot(range(epochs), test_loss,  label='Test loss', c=\"red\")\n",
    "    plt.title('Training and test loss')\n",
    "    plt.legend()\n",
    "    plt.ylim([0, 3])\n",
    "    if save_to_file:\n",
    "        fig.savefig()\n",
    "\n",
    "\n",
    "def plot_accuracies(train_acc, test_acc, save_to_file=None):\n",
    "    fig = plt.figure()\n",
    "    epochs = len(train_acc)\n",
    "    plt.plot(range(epochs), train_acc, 'bo', label='Training accuracy')\n",
    "    plt.plot(range(epochs), test_acc,  label='Test accuracy', c=\"red\")\n",
    "    plt.title('Training and test accuracy')\n",
    "    plt.legend()\n",
    "    plt.ylim([0, 1])\n",
    "    if save_to_file:\n",
    "        fig.savefig(save_to_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_losses(train_loss, test_loss, save_to_file=None)\n",
    "plot_accuracies(train_acc, test_acc, save_to_file=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('Pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fda304a6f307d97b29aaae674164dfd82bf6d6216593c67b562cfafd3100d5c6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
