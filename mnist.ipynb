{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch\n",
    "Ejemplo de clasificador con Pytorch, comentado en espa침ol. \n",
    "\n",
    "El cuaderno de Jupyter se ha desarrollado con Visual Code y puedes encontrar el c칩digo en https://github.com/josegemez/pytorch_mnist \n",
    "\n",
    "Se ha desarrollado en python 3.10.4 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import\n",
    "Con las primeras lineas vamos a importar los paquetes que b치sicos de Pytorch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables Generales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size_train = 128\n",
    "batch_size_test = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformaciones "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms=torchvision.transforms.Compose([\n",
    "                            torchvision.transforms.ToTensor(),\n",
    "                            torchvision.transforms.Normalize((0.1307,), (0.3081,))\n",
    "                            ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_mnist = torchvision.datasets.MNIST('/files/', train=True, download=True, transform=transforms)                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.8 * len(dataset_mnist))\n",
    "test_size = len(dataset_mnist) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset_mnist, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_dataset,  batch_size=batch_size_train, shuffle=True,num_workers=5,pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a ver que \"pinta\" tiene cada elemento del cargador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(train_loader)) #asignamos el primer batch a las variables x e y. La variable X contrendra las imagenes e y contrendra las etiquetas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x es un batch, por lo que la primera dimensi칩n coincidira con el batch size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import imshow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "imshow(x[0].view(28,28).numpy()); # transformamos el primer elemento del batch una matriz de numpy y mostramos con matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 8, 2, 6, 2, 1, 6, 0, 6, 3, 8, 1, 9, 9, 4, 8, 9, 2, 9, 2, 9, 0, 0, 0,\n",
       "        3, 0, 4, 8, 3, 3, 8, 9, 8, 4, 5, 4, 1, 4, 7, 9, 4, 3, 6, 8, 7, 4, 1, 8,\n",
       "        7, 6, 0, 3, 9, 3, 5, 2, 3, 4, 5, 5, 1, 1, 3, 2, 6, 7, 7, 1, 3, 9, 7, 0,\n",
       "        7, 0, 7, 1, 6, 7, 7, 0, 0, 9, 0, 4, 5, 1, 2, 8, 7, 4, 6, 1, 9, 6, 8, 6,\n",
       "        1, 8, 6, 9, 6, 8, 1, 7, 1, 9, 1, 1, 9, 1, 9, 9, 8, 3, 5, 9, 1, 4, 6, 6,\n",
       "        0, 4, 3, 5, 8, 0, 2, 4])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = torch.utils.data.DataLoader(test_dataset,  batch_size=batch_size_test, shuffle=True, num_workers=5,pin_memory=True)              "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya tenemos los datos preparados, ahora vamos a crear la red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate   =   0.01\n",
    "momentum   =   0.5\n",
    "n_epochs = 20\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        n_hidden1 = 128\n",
    "        n_hidden2 = 64\n",
    "        self.fc1 = nn.Linear(28*28,n_hidden1) #capa \"fuly connect\" entrada 28*28 (tama침o de la imagen) 50 neuronas\n",
    "        self.fc1_drop = nn.Dropout(0.2) #dropout (regularizacion) 20% \n",
    "        self.fc2 = nn.Linear(n_hidden1, n_hidden2) #capa fully connect 50 neuronas \n",
    "        self.fc2_drop = nn.Dropout(0.2) #dropout (regularizacion) 20%\n",
    "        self.fc3 = nn.Linear(n_hidden2, 10) #capa de salida numero de salida igual al de etiquetas\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28) #cambia la forma del tensor, -1 para quitar la dimensiones anteriores y dejarlo todo en una vector de 256 elementos\n",
    "        x = F.relu(self.fc1(x)) #capa fully connect y luego activacion relu\n",
    "        x = self.fc1_drop(x) #dropout (regularizacion)\n",
    "        x = F.relu(self.fc2(x)) #capa fully connect y luego activacion relu\n",
    "        x = self.fc2_drop(x) #dropout (regularizacion)\n",
    "        return F.log_softmax(self.fc3(x), dim=1) #soft max (estimacion estadistica 0-1 de la probabildad de que sea de un etiqueta u otra)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2)) \n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = torch.device('cuda')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net().to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate,\n",
    "                      momentum=momentum)\n",
    "\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.5)\n",
    "criterion =  nn.CrossEntropyLoss().to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
       "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
       "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for epoch in range(n_epochs):\n",
    "  epoch_train_loss = []\n",
    "  epoch_train_acc = []\n",
    "  epoch_test_loss = []\n",
    "  epoch_test_acc = []\n",
    "  running_loss = 0.\n",
    "  model.train() #modelo en modo entranamiento\n",
    "   #perdida de la primera epoca\n",
    "  with tqdm(train_loader, unit='batch') as tepoch: #tqdm para ver la barra de progreso por batch\n",
    "    for data, target in tepoch: #en cada batch data la imagen de 28x28 y target la prediccion\n",
    "      model.train(True)\n",
    "      tepoch.set_description(f'Epoch {epoch}') #texto al final de la barra de progreso\n",
    "      data, target = data.to(device=device, non_blocking=True), target.to(device=device, non_blocking=True).long() #se pasan lo datos y las etiquetas al \"device\"\n",
    "      optimizer.zero_grad() #se inicializan los gradientes\n",
    "      output = model(data) #se realiza la predicci칩n propagaci칩n haciea adelante\n",
    "      loss = F.nll_loss(output, target) #se calcula la funcion de perdida entre los valores predichos (output) y los valores reales (target)\n",
    "      pred = output.data.max(1, keepdim=True)[1] #valores predichos\n",
    "      correct = pred.eq(target.data.view_as(pred)).sum()\n",
    "      accuracy = correct.item()/batch_size_train\n",
    "      epoch_train_acc.append(accuracy)\n",
    "      epoch_train_loss.append(loss.cpu().item()) #se guardan el valor de la perdida\n",
    "      loss.backward() #se realiza la retropropagaci칩n \n",
    "      optimizer.step() #se realiza un paso adelante con el learning rate y el gradiente calculado\n",
    "      running_loss += loss.item()\n",
    "      model.train(False)\n",
    "      i, datum = next(enumerate(test_loader))\n",
    "      data, target = datum\n",
    "      data, target = data.to(device=device, non_blocking=True), target.to(device=device, non_blocking=True).long() #se pasan lo datos y las etiquetas al \"device\"\n",
    "      output = model(data) #se realiza la predicci칩n propagaci칩n haciea adelante\n",
    "      t_loss = F.nll_loss(output, target) #se calcula la funcion de perdida entre los valores predichos (output) y los valores reales (target)    \n",
    "      pred = output.data.max(1, keepdim=True)[1] #valores predichos\n",
    "      correct = pred.eq(target.data.view_as(pred)).sum()    \n",
    "      test_accuracy = correct.item()/batch_size_test\n",
    "      epoch_test_acc.append(test_accuracy)\n",
    "      epoch_test_loss.append(t_loss.cpu().item()) #se guardan el valor de la perdida\n",
    "      train_loss.append(np.mean(epoch_train_loss))\n",
    "      test_loss.append(np.mean(epoch_test_loss))\n",
    "      train_acc.append(np.mean(epoch_train_acc))\n",
    "      test_acc.append(np.mean(epoch_test_acc))\n",
    "      if i % 1000 == 999:\n",
    "        print(f'Lost train {running_loss/1000}')\n",
    "  scheduler.step() #se realiza un paso para cambiar el learning rate\n",
    "  print(f'Epoch {epoch}: Train loss {np.mean(epoch_train_loss)} Test loss {np.mean(epoch_test_loss)} Train accuracy {np.mean(epoch_train_acc)} Test accuracy {np.mean(epoch_test_acc)}')\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def train(model, optimizer, loss_fn, train_dl, val_dl, epochs=20, device='cuda'):\n",
    "    '''\n",
    "    Runs training loop for classification problems. Returns Keras-style\n",
    "    per-epoch history of loss and accuracy over training and validation data.\n",
    "\n",
    "    Parametros\n",
    "    ----------\n",
    "    model : nn.Module\n",
    "        Neural network model\n",
    "    optimizer : torch.optim.Optimizer\n",
    "        Search space optimizer (e.g. Adam)\n",
    "    loss_fn :\n",
    "        Funcion de perdida (e.g. nn.CrossEntropyLoss())\n",
    "    train_dl : \n",
    "        Dataloader para los datos de entrenamiento.\n",
    "    val_dl :\n",
    "        Dataloader para los datos de validacion.\n",
    "    epochs : int\n",
    "        Numero de epocas\n",
    "    device : string\n",
    "        'cuda' para entrenamiento en gpu y 'cpu' para entrenamiento en cpu\n",
    "\n",
    "    Retorno\n",
    "    -------\n",
    "    Diccionario\n",
    "        Similar to Keras' fit(), the output dictionary contains per-epoch\n",
    "        history of training loss, training accuracy, validation loss, and\n",
    "        validation accuracy.\n",
    "    '''\n",
    "\n",
    "    print('train() called: model=%s, opt=%s(lr=%f), epochs=%d, device=%s\\n' % \\\n",
    "          (type(model).__name__, type(optimizer).__name__,\n",
    "           optimizer.param_groups[0]['lr'], epochs, device))\n",
    "\n",
    "    history = {} # Collects per-epoch loss and acc like Keras' fit().\n",
    "    history['loss'] = []\n",
    "    history['val_loss'] = []\n",
    "    history['acc'] = []\n",
    "    history['val_acc'] = []\n",
    "\n",
    "    start_time_sec = time.time()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        # --- Entrenamiento en los datos de entrenamientos -----------------------------\n",
    "        model.train() #modelo en forma de entrenamiento    \n",
    "        train_loss         = 0.0 #perdida inicializada en cero\n",
    "        num_train_correct  = 0 #numero de elementos donde la prediccion coincide con la etiqueta \"true positive\"\n",
    "        num_train_examples = 0 #inicializa el numero de elementos sobre los que se ha realizado entrenamiento\n",
    "\n",
    "        for batch in train_dl:\n",
    "\n",
    "            optimizer.zero_grad() #pone los gradientes a cero\n",
    "\n",
    "            x    = batch[0].to(device) #datos al dispositivo (cpu o gpu)\n",
    "            y    = batch[1].to(device) #idem\n",
    "            yhat = model(x) # y predichos \n",
    "            loss = loss_fn(yhat, y) #calcula la perdida entre los \"y predichos\" y los \"y etiquetas\"\n",
    "\n",
    "            loss.backward() #retropropagaci칩n\n",
    "            optimizer.step() #se mueve el gradiente un paso (learning rate por el gradiente negativo)\n",
    "\n",
    "            train_loss         += loss.data.item() * x.size(0) \n",
    "            num_train_correct  += (torch.max(yhat, 1)[1] == y).sum().item() #compureba los elementos correctos\n",
    "            num_train_examples += x.shape[0]\n",
    "\n",
    "        train_acc   = num_train_correct / num_train_examples\n",
    "        train_loss  = train_loss / len(train_dl.dataset)\n",
    "\n",
    "\n",
    "        # --- Evaluacion en los datos de test -------------------------------------\n",
    "        model.eval()\n",
    "        val_loss       = 0.0\n",
    "        num_val_correct  = 0\n",
    "        num_val_examples = 0\n",
    "\n",
    "        for batch in val_dl:\n",
    "\n",
    "            x    = batch[0].to(device)\n",
    "            y    = batch[1].to(device)\n",
    "            yhat = model(x)\n",
    "            loss = loss_fn(yhat, y)\n",
    "\n",
    "            val_loss         += loss.data.item() * x.size(0)\n",
    "            num_val_correct  += (torch.max(yhat, 1)[1] == y).sum().item()\n",
    "            num_val_examples += y.shape[0]\n",
    "\n",
    "        val_acc  = num_val_correct / num_val_examples\n",
    "        val_loss = val_loss / len(val_dl.dataset)\n",
    "\n",
    "\n",
    "        print('Epoch %3d/%3d, train loss: %5.2f, train acc: %5.2f, val loss: %5.2f, val acc: %5.2f' % \\\n",
    "              (epoch+1, epochs, train_loss, train_acc, val_loss, val_acc))\n",
    "\n",
    "        history['loss'].append(train_loss)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['acc'].append(train_acc)\n",
    "        history['val_acc'].append(val_acc)\n",
    "\n",
    "    # END OF TRAINING LOOP\n",
    "\n",
    "\n",
    "    end_time_sec       = time.time()\n",
    "    total_time_sec     = end_time_sec - start_time_sec\n",
    "    time_per_epoch_sec = total_time_sec / epochs\n",
    "    print()\n",
    "    print('Time total:     %5.2f sec' % (total_time_sec))\n",
    "    print('Time per epoch: %5.2f sec' % (time_per_epoch_sec))\n",
    "\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train() called: model=Net, opt=SGD(lr=0.010000), epochs=20, device=cuda\n",
      "\n",
      "Epoch   1/ 20, train loss:  1.36, train acc:  0.53, val loss:  0.35, val acc:  0.91\n",
      "Epoch   2/ 20, train loss:  0.56, train acc:  0.83, val loss:  0.22, val acc:  0.94\n",
      "Epoch   3/ 20, train loss:  0.43, train acc:  0.87, val loss:  0.17, val acc:  0.95\n",
      "Epoch   4/ 20, train loss:  0.37, train acc:  0.89, val loss:  0.14, val acc:  0.96\n",
      "Epoch   5/ 20, train loss:  0.33, train acc:  0.90, val loss:  0.13, val acc:  0.96\n",
      "Epoch   6/ 20, train loss:  0.30, train acc:  0.91, val loss:  0.12, val acc:  0.96\n",
      "Epoch   7/ 20, train loss:  0.28, train acc:  0.92, val loss:  0.11, val acc:  0.97\n",
      "Epoch   8/ 20, train loss:  0.26, train acc:  0.92, val loss:  0.10, val acc:  0.97\n",
      "Epoch   9/ 20, train loss:  0.25, train acc:  0.93, val loss:  0.10, val acc:  0.97\n",
      "Epoch  10/ 20, train loss:  0.24, train acc:  0.93, val loss:  0.09, val acc:  0.97\n",
      "Epoch  11/ 20, train loss:  0.23, train acc:  0.93, val loss:  0.09, val acc:  0.97\n",
      "Epoch  12/ 20, train loss:  0.22, train acc:  0.93, val loss:  0.08, val acc:  0.97\n",
      "Epoch  13/ 20, train loss:  0.21, train acc:  0.94, val loss:  0.08, val acc:  0.98\n",
      "Epoch  14/ 20, train loss:  0.20, train acc:  0.94, val loss:  0.08, val acc:  0.97\n",
      "Epoch  15/ 20, train loss:  0.20, train acc:  0.94, val loss:  0.08, val acc:  0.98\n",
      "Epoch  16/ 20, train loss:  0.19, train acc:  0.94, val loss:  0.07, val acc:  0.98\n",
      "Epoch  17/ 20, train loss:  0.19, train acc:  0.94, val loss:  0.07, val acc:  0.98\n",
      "Epoch  18/ 20, train loss:  0.19, train acc:  0.95, val loss:  0.07, val acc:  0.98\n",
      "Epoch  19/ 20, train loss:  0.18, train acc:  0.95, val loss:  0.07, val acc:  0.98\n",
      "Epoch  20/ 20, train loss:  0.18, train acc:  0.95, val loss:  0.07, val acc:  0.98\n",
      "\n",
      "Time total:     327.35 sec\n",
      "Time per epoch: 16.37 sec\n"
     ]
    }
   ],
   "source": [
    "history = train(model,optimizer,criterion, train_loader, test_loader, n_epochs, 'cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'results/model.pth')\n",
    "torch.save(optimizer.state_dict(), 'results/optimizer.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('results/model.pth'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "epochs = len(train_loss)\n",
    "plt.plot(range(len(history['loss'])), history['loss'], 'bo', label='Training loss')\n",
    "plt.plot(range(len(history['val_loss'])), history['val_loss'], c=\"red\",label='Val loss')\n",
    "plt.title('Training and test loss')\n",
    "plt.legend()\n",
    "plt.ylim([0, 3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "epochs = len(train_loss)\n",
    "plt.plot(range(len(history['acc'])), history['acc'], 'bo', label='Training acc')\n",
    "plt.plot(range(len(history['val_acc'])), history['val_acc'], c=\"red\",label='Val acc')\n",
    "plt.title('Training and test acc')\n",
    "plt.legend()\n",
    "plt.ylim([0, 1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('Pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fda304a6f307d97b29aaae674164dfd82bf6d6216593c67b562cfafd3100d5c6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
