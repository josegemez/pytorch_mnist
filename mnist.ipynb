{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch\n",
    "Ejemplo de clasificador con Pytorch, comentado en español. \n",
    "\n",
    "El cuaderno de Jupyter se ha desarrollado con Visual Code y puedes encontrar el código en https://github.com/josegemez/pytorch_mnist \n",
    "\n",
    "Se ha desarrollado en python 3.10.4 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import\n",
    "Con las primeras lineas vamos a importar los paquetes que básicos de Pytorch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables Generales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size_train = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformaciones "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms=torchvision.transforms.Compose([\n",
    "                            torchvision.transforms.ToTensor(),\n",
    "                            torchvision.transforms.Normalize((0.1307,), (0.3081,))\n",
    "                            ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_mnist = torchvision.datasets.MNIST('/files/', train=True, download=True, transform=transforms)                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset_mnist,  batch_size=batch_size_train, shuffle=True,num_workers=1,pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a ver que \"pinta\" tiene cada elemento del cargador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(train_loader)) #asignamos el primer batch a las variables x e y. La variable X contrendra las imagenes e y contrendra las etiquetas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x es un batch, por lo que la primera dimensión coincidira con el batch size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import imshow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(x[0].view(28,28).numpy()); # transformamos el primer elemento del batch una matriz de numpy y mostramos con matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_mnist_test = torchvision.datasets.MNIST('/files/', train=False, download=True, transform=transforms)  # Train ahora se pone en False    \n",
    "test_loader = torch.utils.data.DataLoader(dataset_mnist_test,  batch_size=batch_size_train, shuffle=True)              "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya tenemos los datos preparados, ahora vamos a crear la red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate   =   0.01\n",
    "momentum   =   0.5\n",
    "n_epochs = 5\n",
    "log_interval   =   10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(28*28, 50) #capa \"fuly connect\" entrada 28*28 (tamaño de la imagen) 50 neuronas\n",
    "        self.fc1_drop = nn.Dropout(0.2) #dropout (regularizacion) 20% \n",
    "        self.fc2 = nn.Linear(50, 50) #capa fully connect 50 neuronas \n",
    "        self.fc2_drop = nn.Dropout(0.2) #dropout (regularizacion) 20%\n",
    "        self.fc3 = nn.Linear(50, 10) #capa de salida numero de salida igual al de etiquetas\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28) #cambia la forma del tensor, -1 para quitar la dimensiones anteriores y dejarlo todo en una vector de 256 elementos\n",
    "        x = F.relu(self.fc1(x)) #capa fully connect y luego activacion relu\n",
    "        x = self.fc1_drop(x) #dropout (regularizacion)\n",
    "        x = F.relu(self.fc2(x)) #capa fully connect y luego activacion relu\n",
    "        x = self.fc2_drop(x) #dropout (regularizacion)\n",
    "        return F.log_softmax(self.fc3(x), dim=1) #soft max (estimacion estadistica 0-1 de la probabildad de que sea de un etiqueta u otra)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2)) \n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = torch.device('cuda')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net().to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate,\n",
    "                      momentum=momentum)\n",
    "\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.5)\n",
    "criterion =  nn.CrossEntropyLoss().to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = []\n",
    "test_loss = []\n",
    "train_acc = []\n",
    "test_acc = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(n_epochs):\n",
    "  epoch_train_loss = []\n",
    "  epoch_train_acc = []\n",
    "  epoch_test_loss = []\n",
    "  epoch_test_acc = []\n",
    "  model.train() #modelo en modo entranamiento\n",
    "   #perdida de la primera epoca\n",
    "  with tqdm(train_loader, unit='batch') as tepoch: #tqdm para ver la barra de progreso por batch\n",
    "    for data, target in tepoch: #en cada batch data la imagen de 28x28 y target la prediccion\n",
    "      model.train()\n",
    "      tepoch.set_description(f'Epoch {epoch}') #texto al final de la barra de progreso\n",
    "      data, target = data.to(device=device, non_blocking=True), target.to(device=device, non_blocking=True).long() #se pasan lo datos y las etiquetas al \"device\"\n",
    "      optimizer.zero_grad() #se inicializan los gradientes\n",
    "      output = model(data) #se realiza la predicción propagación haciea adelante\n",
    "      loss = F.nll_loss(output, target) #se calcula la funcion de perdida entre los valores predichos (output) y los valores reales (target)\n",
    "      pred = output.data.max(1, keepdim=True)[1] #valores predichos\n",
    "      correct = pred.eq(target.data.view_as(pred)).sum()\n",
    "      accuracy = correct.item()/batch_size_train\n",
    "      epoch_train_acc.append(accuracy)\n",
    "      epoch_train_loss.append(loss.cpu().item()) #se guardan el valor de la perdida\n",
    "      loss.backward() #se realiza la retropropagación \n",
    "      optimizer.step() #se realiza un paso adelante con el learning rate y el gradiente calculado\n",
    "\n",
    "  model.eval()\n",
    "  with tqdm(test_loader, unit='batch') as tepoch:\n",
    "    with torch.no_grad():\n",
    "      for data, target in tepoch:\n",
    "        data, target = data.to(device=device, non_blocking=True), target.to(device=device, non_blocking=True).long() #se pasan lo datos y las etiquetas al \"device\"\n",
    "        output = model(data) #se realiza la predicción propagación haciea adelante\n",
    "        t_loss = F.nll_loss(output, target) #se calcula la funcion de perdida entre los valores predichos (output) y los valores reales (target)    \n",
    "        pred = output.data.max(1, keepdim=True)[1] #valores predichos\n",
    "        correct = pred.eq(target.data.view_as(pred)).sum()    \n",
    "        test_accuracy = correct.item()/batch_size_train\n",
    "        epoch_test_acc.append(test_accuracy)\n",
    "        epoch_test_loss.append(t_loss.cpu().item()) #se guardan el valor de la perdida\n",
    "  scheduler.step() #se realiza un paso para cambiar el learning rate\n",
    "  print(f'Epoch {epoch}: Train loss {np.mean(epoch_train_loss)} Test loss {np.mean(epoch_test_loss)} Train accuracy {np.mean(epoch_train_acc)} Test accuracy {np.mean(epoch_test_acc)}')\n",
    "  train_loss.append(np.mean(epoch_train_loss))\n",
    "  test_loss.append(np.mean(epoch_test_loss))\n",
    "  train_acc.append(np.mean(epoch_train_acc))\n",
    "  test_acc.append(np.mean(epoch_test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_losses(train_loss, test_loss, save_to_file=None):\n",
    "    fig = plt.figure()\n",
    "    epochs = len(train_loss)\n",
    "    plt.plot(range(epochs), train_loss, 'bo', label='Training loss')\n",
    "    plt.plot(range(epochs), test_loss,  label='Test loss', c=\"red\")\n",
    "    plt.title('Training and test loss')\n",
    "    plt.legend()\n",
    "    plt.ylim([0, 3])\n",
    "    if save_to_file:\n",
    "        fig.savefig()\n",
    "\n",
    "\n",
    "def plot_accuracies(train_acc, test_acc, save_to_file=None):\n",
    "    fig = plt.figure()\n",
    "    epochs = len(train_acc)\n",
    "    plt.plot(range(epochs), train_acc, 'bo', label='Training accuracy')\n",
    "    plt.plot(range(epochs), test_acc,  label='Test accuracy', c=\"red\")\n",
    "    plt.title('Training and test accuracy')\n",
    "    plt.legend()\n",
    "    plt.ylim([0, 1])\n",
    "    if save_to_file:\n",
    "        fig.savefig(save_to_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_losses(train_loss, test_loss, save_to_file=None)\n",
    "plot_accuracies(train_acc, test_acc, save_to_file=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('Pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fda304a6f307d97b29aaae674164dfd82bf6d6216593c67b562cfafd3100d5c6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
