{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch\n",
    "Ejemplo de clasificador con Pytorch, comentado en espa침ol. \n",
    "\n",
    "El cuaderno de Jupyter se ha desarrollado con Visual Code y puedes encontrar el c칩digo en https://github.com/josegemez/pytorch_mnist \n",
    "\n",
    "Se ha desarrollado en python 3.10.4 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import\n",
    "Con las primeras lineas vamos a importar los paquetes que b치sicos de Pytorch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables Generales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size_train = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformaciones "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms=torchvision.transforms.Compose([\n",
    "                            torchvision.transforms.ToTensor(),\n",
    "                            torchvision.transforms.Normalize((0.1307,), (0.3081,))\n",
    "                            ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_mnist = torchvision.datasets.MNIST('/files/', train=True, download=True, transform=transforms)                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset_mnist,  batch_size=batch_size_train, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a ver que \"pinta\" tiene cada elemento del cargador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(train_loader)) #asignamos el primer batch a las variables x e y. La variable X contrendra las imagenes e y contrendra las etiquetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 1, 28, 28])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x es un batch, por lo que la primera dimensi칩n coincidira con el batch size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import imshow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "imshow(x[0].view(28,28).numpy()); # transformamos el primer elemento del batch una matriz de numpy y mostramos con matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5, 3, 5, 5, 3, 0, 7, 0, 5, 9, 0, 0, 7, 8, 0, 3, 9, 1, 9, 7, 1, 2, 3, 9,\n",
       "        1, 3, 5, 1, 4, 1, 5, 4, 5, 6, 2, 8, 0, 4, 5, 1, 5, 9, 7, 2, 7, 9, 5, 2,\n",
       "        2, 1, 8, 4, 3, 2, 7, 7, 0, 4, 6, 6, 5, 4, 3, 0, 9, 9, 4, 4, 8, 4, 3, 4,\n",
       "        1, 8, 4, 5, 6, 0, 4, 4, 5, 5, 3, 4, 9, 9, 8, 9, 1, 4, 6, 4, 2, 3, 4, 5,\n",
       "        6, 1, 7, 8, 0, 8, 2, 3, 6, 8, 3, 6, 9, 8, 4, 9, 2, 0, 6, 4, 4, 7, 9, 6,\n",
       "        2, 3, 7, 1, 9, 2, 4, 1])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_mnist_test = torchvision.datasets.MNIST('/files/', train=False, download=True, transform=transforms)  # Train ahora se pone en False    \n",
    "test_loader = torch.utils.data.DataLoader(dataset_mnist,  batch_size=batch_size_train, shuffle=True)              "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya tenemos los datos preparados, ahora vamos a crear la red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate   =   0.01\n",
    "momentum   =   0.5\n",
    "n_epochs = 5\n",
    "log_interval   =   10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2)) \n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net().to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate,\n",
    "                      momentum=momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
       "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
       "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "train_counter = []\n",
    "test_losses = []\n",
    "test_counter = [i*len(train_loader.dataset) for i in range(n_epochs + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = torch.device('cuda')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "  model.train()\n",
    "  for batch_idx, (data, target) in enumerate(train_loader):\n",
    "    data, target = data.to(device=device), target.to(device=device)\n",
    "    optimizer.zero_grad()\n",
    "    output = model(data)\n",
    "    loss = F.nll_loss(output, target)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if batch_idx % log_interval == 0:\n",
    "      print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "        epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "        100. * batch_idx / len(train_loader), loss.item()))\n",
    "      train_losses.append(loss.item())\n",
    "      train_counter.append(\n",
    "        (batch_idx*64) + ((epoch-1)*len(train_loader.dataset)))\n",
    "      torch.save(model.state_dict(), 'results/model.pth')\n",
    "      torch.save(optimizer.state_dict(), 'results/optimizer.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "  model.eval()\n",
    "  test_loss = 0\n",
    "  correct = 0\n",
    "  with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "      data, target = data.to(device=device), target.to(device=device)\n",
    "      output = model(data)\n",
    "      test_loss += F.nll_loss(output, target, size_average=False).item()\n",
    "      pred = output.data.max(1, keepdim=True)[1]\n",
    "      correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "  test_loss /= len(test_loader.dataset)\n",
    "  test_losses.append(test_loss)\n",
    "  print('\\nTest set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "    test_loss, correct, len(test_loader.dataset),\n",
    "    100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jose\\AppData\\Local\\Temp\\ipykernel_22864\\746712537.py:17: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.404212\n",
      "Train Epoch: 1 [1280/60000 (2%)]\tLoss: 0.291219\n",
      "Train Epoch: 1 [2560/60000 (4%)]\tLoss: 0.225978\n",
      "Train Epoch: 1 [3840/60000 (6%)]\tLoss: 0.360579\n",
      "Train Epoch: 1 [5120/60000 (9%)]\tLoss: 0.293713\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.460779\n",
      "Train Epoch: 1 [7680/60000 (13%)]\tLoss: 0.208715\n",
      "Train Epoch: 1 [8960/60000 (15%)]\tLoss: 0.253121\n",
      "Train Epoch: 1 [10240/60000 (17%)]\tLoss: 0.270561\n",
      "Train Epoch: 1 [11520/60000 (19%)]\tLoss: 0.338272\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.214927\n",
      "Train Epoch: 1 [14080/60000 (23%)]\tLoss: 0.171565\n",
      "Train Epoch: 1 [15360/60000 (26%)]\tLoss: 0.300624\n",
      "Train Epoch: 1 [16640/60000 (28%)]\tLoss: 0.357604\n",
      "Train Epoch: 1 [17920/60000 (30%)]\tLoss: 0.283089\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.198476\n",
      "Train Epoch: 1 [20480/60000 (34%)]\tLoss: 0.159070\n",
      "Train Epoch: 1 [21760/60000 (36%)]\tLoss: 0.293819\n",
      "Train Epoch: 1 [23040/60000 (38%)]\tLoss: 0.227059\n",
      "Train Epoch: 1 [24320/60000 (41%)]\tLoss: 0.235513\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.314179\n",
      "Train Epoch: 1 [26880/60000 (45%)]\tLoss: 0.309818\n",
      "Train Epoch: 1 [28160/60000 (47%)]\tLoss: 0.227373\n",
      "Train Epoch: 1 [29440/60000 (49%)]\tLoss: 0.230821\n",
      "Train Epoch: 1 [30720/60000 (51%)]\tLoss: 0.268564\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.192361\n",
      "Train Epoch: 1 [33280/60000 (55%)]\tLoss: 0.326095\n",
      "Train Epoch: 1 [34560/60000 (58%)]\tLoss: 0.242101\n",
      "Train Epoch: 1 [35840/60000 (60%)]\tLoss: 0.416962\n",
      "Train Epoch: 1 [37120/60000 (62%)]\tLoss: 0.238854\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.290950\n",
      "Train Epoch: 1 [39680/60000 (66%)]\tLoss: 0.309576\n",
      "Train Epoch: 1 [40960/60000 (68%)]\tLoss: 0.331459\n",
      "Train Epoch: 1 [42240/60000 (70%)]\tLoss: 0.194403\n",
      "Train Epoch: 1 [43520/60000 (72%)]\tLoss: 0.220432\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.208330\n",
      "Train Epoch: 1 [46080/60000 (77%)]\tLoss: 0.179419\n",
      "Train Epoch: 1 [47360/60000 (79%)]\tLoss: 0.382370\n",
      "Train Epoch: 1 [48640/60000 (81%)]\tLoss: 0.221244\n",
      "Train Epoch: 1 [49920/60000 (83%)]\tLoss: 0.218745\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.324350\n",
      "Train Epoch: 1 [52480/60000 (87%)]\tLoss: 0.387870\n",
      "Train Epoch: 1 [53760/60000 (90%)]\tLoss: 0.237975\n",
      "Train Epoch: 1 [55040/60000 (92%)]\tLoss: 0.266228\n",
      "Train Epoch: 1 [56320/60000 (94%)]\tLoss: 0.291363\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.232798\n",
      "Train Epoch: 1 [58880/60000 (98%)]\tLoss: 0.130743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jose\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.1015, Accuracy: 58140/60000 (97%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.290193\n",
      "Train Epoch: 2 [1280/60000 (2%)]\tLoss: 0.296355\n",
      "Train Epoch: 2 [2560/60000 (4%)]\tLoss: 0.289227\n",
      "Train Epoch: 2 [3840/60000 (6%)]\tLoss: 0.232863\n",
      "Train Epoch: 2 [5120/60000 (9%)]\tLoss: 0.255078\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.270220\n",
      "Train Epoch: 2 [7680/60000 (13%)]\tLoss: 0.284517\n",
      "Train Epoch: 2 [8960/60000 (15%)]\tLoss: 0.293392\n",
      "Train Epoch: 2 [10240/60000 (17%)]\tLoss: 0.232994\n",
      "Train Epoch: 2 [11520/60000 (19%)]\tLoss: 0.279123\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.225431\n",
      "Train Epoch: 2 [14080/60000 (23%)]\tLoss: 0.239266\n",
      "Train Epoch: 2 [15360/60000 (26%)]\tLoss: 0.296275\n",
      "Train Epoch: 2 [16640/60000 (28%)]\tLoss: 0.272007\n",
      "Train Epoch: 2 [17920/60000 (30%)]\tLoss: 0.167046\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.329694\n",
      "Train Epoch: 2 [20480/60000 (34%)]\tLoss: 0.221038\n",
      "Train Epoch: 2 [21760/60000 (36%)]\tLoss: 0.198694\n",
      "Train Epoch: 2 [23040/60000 (38%)]\tLoss: 0.294684\n",
      "Train Epoch: 2 [24320/60000 (41%)]\tLoss: 0.296202\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.376157\n",
      "Train Epoch: 2 [26880/60000 (45%)]\tLoss: 0.287428\n",
      "Train Epoch: 2 [28160/60000 (47%)]\tLoss: 0.298766\n",
      "Train Epoch: 2 [29440/60000 (49%)]\tLoss: 0.277978\n",
      "Train Epoch: 2 [30720/60000 (51%)]\tLoss: 0.203806\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.285406\n",
      "Train Epoch: 2 [33280/60000 (55%)]\tLoss: 0.278481\n",
      "Train Epoch: 2 [34560/60000 (58%)]\tLoss: 0.162574\n",
      "Train Epoch: 2 [35840/60000 (60%)]\tLoss: 0.187965\n",
      "Train Epoch: 2 [37120/60000 (62%)]\tLoss: 0.200413\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.261875\n",
      "Train Epoch: 2 [39680/60000 (66%)]\tLoss: 0.257864\n",
      "Train Epoch: 2 [40960/60000 (68%)]\tLoss: 0.206114\n",
      "Train Epoch: 2 [42240/60000 (70%)]\tLoss: 0.265863\n",
      "Train Epoch: 2 [43520/60000 (72%)]\tLoss: 0.273622\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.114988\n",
      "Train Epoch: 2 [46080/60000 (77%)]\tLoss: 0.449480\n",
      "Train Epoch: 2 [47360/60000 (79%)]\tLoss: 0.220214\n",
      "Train Epoch: 2 [48640/60000 (81%)]\tLoss: 0.203480\n",
      "Train Epoch: 2 [49920/60000 (83%)]\tLoss: 0.325786\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.308008\n",
      "Train Epoch: 2 [52480/60000 (87%)]\tLoss: 0.212065\n",
      "Train Epoch: 2 [53760/60000 (90%)]\tLoss: 0.300581\n",
      "Train Epoch: 2 [55040/60000 (92%)]\tLoss: 0.182047\n",
      "Train Epoch: 2 [56320/60000 (94%)]\tLoss: 0.320206\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.226182\n",
      "Train Epoch: 2 [58880/60000 (98%)]\tLoss: 0.308797\n",
      "\n",
      "Test set: Avg. loss: 0.0939, Accuracy: 58283/60000 (97%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.113687\n",
      "Train Epoch: 3 [1280/60000 (2%)]\tLoss: 0.240465\n",
      "Train Epoch: 3 [2560/60000 (4%)]\tLoss: 0.152611\n",
      "Train Epoch: 3 [3840/60000 (6%)]\tLoss: 0.285854\n",
      "Train Epoch: 3 [5120/60000 (9%)]\tLoss: 0.172361\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.188495\n",
      "Train Epoch: 3 [7680/60000 (13%)]\tLoss: 0.213099\n",
      "Train Epoch: 3 [8960/60000 (15%)]\tLoss: 0.359279\n",
      "Train Epoch: 3 [10240/60000 (17%)]\tLoss: 0.199608\n",
      "Train Epoch: 3 [11520/60000 (19%)]\tLoss: 0.271993\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.244845\n",
      "Train Epoch: 3 [14080/60000 (23%)]\tLoss: 0.438413\n",
      "Train Epoch: 3 [15360/60000 (26%)]\tLoss: 0.173281\n",
      "Train Epoch: 3 [16640/60000 (28%)]\tLoss: 0.325684\n",
      "Train Epoch: 3 [17920/60000 (30%)]\tLoss: 0.334470\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.272022\n",
      "Train Epoch: 3 [20480/60000 (34%)]\tLoss: 0.235971\n",
      "Train Epoch: 3 [21760/60000 (36%)]\tLoss: 0.274613\n",
      "Train Epoch: 3 [23040/60000 (38%)]\tLoss: 0.183663\n",
      "Train Epoch: 3 [24320/60000 (41%)]\tLoss: 0.232849\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.329078\n",
      "Train Epoch: 3 [26880/60000 (45%)]\tLoss: 0.370934\n",
      "Train Epoch: 3 [28160/60000 (47%)]\tLoss: 0.166421\n",
      "Train Epoch: 3 [29440/60000 (49%)]\tLoss: 0.321239\n",
      "Train Epoch: 3 [30720/60000 (51%)]\tLoss: 0.249524\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.307810\n",
      "Train Epoch: 3 [33280/60000 (55%)]\tLoss: 0.278135\n",
      "Train Epoch: 3 [34560/60000 (58%)]\tLoss: 0.348417\n",
      "Train Epoch: 3 [35840/60000 (60%)]\tLoss: 0.269224\n",
      "Train Epoch: 3 [37120/60000 (62%)]\tLoss: 0.167401\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.224964\n",
      "Train Epoch: 3 [39680/60000 (66%)]\tLoss: 0.209272\n",
      "Train Epoch: 3 [40960/60000 (68%)]\tLoss: 0.242820\n",
      "Train Epoch: 3 [42240/60000 (70%)]\tLoss: 0.300533\n",
      "Train Epoch: 3 [43520/60000 (72%)]\tLoss: 0.196346\n",
      "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.253650\n",
      "Train Epoch: 3 [46080/60000 (77%)]\tLoss: 0.376810\n",
      "Train Epoch: 3 [47360/60000 (79%)]\tLoss: 0.307180\n",
      "Train Epoch: 3 [48640/60000 (81%)]\tLoss: 0.201819\n",
      "Train Epoch: 3 [49920/60000 (83%)]\tLoss: 0.174548\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.170745\n",
      "Train Epoch: 3 [52480/60000 (87%)]\tLoss: 0.249358\n",
      "Train Epoch: 3 [53760/60000 (90%)]\tLoss: 0.230731\n",
      "Train Epoch: 3 [55040/60000 (92%)]\tLoss: 0.184607\n",
      "Train Epoch: 3 [56320/60000 (94%)]\tLoss: 0.340181\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.350860\n",
      "Train Epoch: 3 [58880/60000 (98%)]\tLoss: 0.188542\n",
      "\n",
      "Test set: Avg. loss: 0.0875, Accuracy: 58402/60000 (97%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.210705\n",
      "Train Epoch: 4 [1280/60000 (2%)]\tLoss: 0.334118\n",
      "Train Epoch: 4 [2560/60000 (4%)]\tLoss: 0.221520\n",
      "Train Epoch: 4 [3840/60000 (6%)]\tLoss: 0.164284\n",
      "Train Epoch: 4 [5120/60000 (9%)]\tLoss: 0.185012\n",
      "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.270984\n",
      "Train Epoch: 4 [7680/60000 (13%)]\tLoss: 0.193975\n",
      "Train Epoch: 4 [8960/60000 (15%)]\tLoss: 0.219022\n",
      "Train Epoch: 4 [10240/60000 (17%)]\tLoss: 0.281993\n",
      "Train Epoch: 4 [11520/60000 (19%)]\tLoss: 0.237138\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.270815\n",
      "Train Epoch: 4 [14080/60000 (23%)]\tLoss: 0.185997\n",
      "Train Epoch: 4 [15360/60000 (26%)]\tLoss: 0.189838\n",
      "Train Epoch: 4 [16640/60000 (28%)]\tLoss: 0.254473\n",
      "Train Epoch: 4 [17920/60000 (30%)]\tLoss: 0.239712\n",
      "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.148539\n",
      "Train Epoch: 4 [20480/60000 (34%)]\tLoss: 0.449793\n",
      "Train Epoch: 4 [21760/60000 (36%)]\tLoss: 0.179662\n",
      "Train Epoch: 4 [23040/60000 (38%)]\tLoss: 0.278429\n",
      "Train Epoch: 4 [24320/60000 (41%)]\tLoss: 0.226133\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.153487\n",
      "Train Epoch: 4 [26880/60000 (45%)]\tLoss: 0.393617\n",
      "Train Epoch: 4 [28160/60000 (47%)]\tLoss: 0.110401\n",
      "Train Epoch: 4 [29440/60000 (49%)]\tLoss: 0.130432\n",
      "Train Epoch: 4 [30720/60000 (51%)]\tLoss: 0.334454\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.172978\n",
      "Train Epoch: 4 [33280/60000 (55%)]\tLoss: 0.267987\n",
      "Train Epoch: 4 [34560/60000 (58%)]\tLoss: 0.188366\n",
      "Train Epoch: 4 [35840/60000 (60%)]\tLoss: 0.251469\n",
      "Train Epoch: 4 [37120/60000 (62%)]\tLoss: 0.079182\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.342831\n",
      "Train Epoch: 4 [39680/60000 (66%)]\tLoss: 0.153445\n",
      "Train Epoch: 4 [40960/60000 (68%)]\tLoss: 0.221464\n",
      "Train Epoch: 4 [42240/60000 (70%)]\tLoss: 0.257080\n",
      "Train Epoch: 4 [43520/60000 (72%)]\tLoss: 0.162138\n",
      "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.202356\n",
      "Train Epoch: 4 [46080/60000 (77%)]\tLoss: 0.228605\n",
      "Train Epoch: 4 [47360/60000 (79%)]\tLoss: 0.334075\n",
      "Train Epoch: 4 [48640/60000 (81%)]\tLoss: 0.134292\n",
      "Train Epoch: 4 [49920/60000 (83%)]\tLoss: 0.205744\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.244820\n",
      "Train Epoch: 4 [52480/60000 (87%)]\tLoss: 0.248662\n",
      "Train Epoch: 4 [53760/60000 (90%)]\tLoss: 0.403791\n",
      "Train Epoch: 4 [55040/60000 (92%)]\tLoss: 0.261247\n",
      "Train Epoch: 4 [56320/60000 (94%)]\tLoss: 0.276845\n",
      "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.157884\n",
      "Train Epoch: 4 [58880/60000 (98%)]\tLoss: 0.389150\n",
      "\n",
      "Test set: Avg. loss: 0.0838, Accuracy: 58477/60000 (97%)\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.095428\n",
      "Train Epoch: 5 [1280/60000 (2%)]\tLoss: 0.159529\n",
      "Train Epoch: 5 [2560/60000 (4%)]\tLoss: 0.333516\n",
      "Train Epoch: 5 [3840/60000 (6%)]\tLoss: 0.424193\n",
      "Train Epoch: 5 [5120/60000 (9%)]\tLoss: 0.277497\n",
      "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.179001\n",
      "Train Epoch: 5 [7680/60000 (13%)]\tLoss: 0.216369\n",
      "Train Epoch: 5 [8960/60000 (15%)]\tLoss: 0.157873\n",
      "Train Epoch: 5 [10240/60000 (17%)]\tLoss: 0.215034\n",
      "Train Epoch: 5 [11520/60000 (19%)]\tLoss: 0.220281\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.210856\n",
      "Train Epoch: 5 [14080/60000 (23%)]\tLoss: 0.291214\n",
      "Train Epoch: 5 [15360/60000 (26%)]\tLoss: 0.313569\n",
      "Train Epoch: 5 [16640/60000 (28%)]\tLoss: 0.261261\n",
      "Train Epoch: 5 [17920/60000 (30%)]\tLoss: 0.186467\n",
      "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.186755\n",
      "Train Epoch: 5 [20480/60000 (34%)]\tLoss: 0.215538\n",
      "Train Epoch: 5 [21760/60000 (36%)]\tLoss: 0.264616\n",
      "Train Epoch: 5 [23040/60000 (38%)]\tLoss: 0.321407\n",
      "Train Epoch: 5 [24320/60000 (41%)]\tLoss: 0.173506\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.194585\n",
      "Train Epoch: 5 [26880/60000 (45%)]\tLoss: 0.302882\n",
      "Train Epoch: 5 [28160/60000 (47%)]\tLoss: 0.143588\n",
      "Train Epoch: 5 [29440/60000 (49%)]\tLoss: 0.199782\n",
      "Train Epoch: 5 [30720/60000 (51%)]\tLoss: 0.379644\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.304058\n",
      "Train Epoch: 5 [33280/60000 (55%)]\tLoss: 0.264917\n",
      "Train Epoch: 5 [34560/60000 (58%)]\tLoss: 0.163013\n",
      "Train Epoch: 5 [35840/60000 (60%)]\tLoss: 0.241395\n",
      "Train Epoch: 5 [37120/60000 (62%)]\tLoss: 0.240462\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.184631\n",
      "Train Epoch: 5 [39680/60000 (66%)]\tLoss: 0.193677\n",
      "Train Epoch: 5 [40960/60000 (68%)]\tLoss: 0.136389\n",
      "Train Epoch: 5 [42240/60000 (70%)]\tLoss: 0.195031\n",
      "Train Epoch: 5 [43520/60000 (72%)]\tLoss: 0.208150\n",
      "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.202659\n",
      "Train Epoch: 5 [46080/60000 (77%)]\tLoss: 0.216071\n",
      "Train Epoch: 5 [47360/60000 (79%)]\tLoss: 0.188558\n",
      "Train Epoch: 5 [48640/60000 (81%)]\tLoss: 0.215095\n",
      "Train Epoch: 5 [49920/60000 (83%)]\tLoss: 0.276694\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.197031\n",
      "Train Epoch: 5 [52480/60000 (87%)]\tLoss: 0.219430\n",
      "Train Epoch: 5 [53760/60000 (90%)]\tLoss: 0.287162\n",
      "Train Epoch: 5 [55040/60000 (92%)]\tLoss: 0.130849\n",
      "Train Epoch: 5 [56320/60000 (94%)]\tLoss: 0.327777\n",
      "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.132339\n",
      "Train Epoch: 5 [58880/60000 (98%)]\tLoss: 0.217584\n",
      "\n",
      "Test set: Avg. loss: 0.0793, Accuracy: 58594/60000 (98%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, n_epochs + 1):\n",
    "  train(epoch)\n",
    "  test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must be the same size",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32md:\\code\\pytorch_mnist\\mnist.ipynb Cell 33\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/code/pytorch_mnist/mnist.ipynb#X51sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m fig \u001b[39m=\u001b[39m plt\u001b[39m.\u001b[39mfigure()\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/code/pytorch_mnist/mnist.ipynb#X51sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m plt\u001b[39m.\u001b[39mplot(train_counter, train_losses, color\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mblue\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/code/pytorch_mnist/mnist.ipynb#X51sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m plt\u001b[39m.\u001b[39;49mscatter(test_counter, test_losses, color\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mred\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/code/pytorch_mnist/mnist.ipynb#X51sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m plt\u001b[39m.\u001b[39mlegend([\u001b[39m'\u001b[39m\u001b[39mTrain Loss\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mTest Loss\u001b[39m\u001b[39m'\u001b[39m], loc\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mupper right\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/code/pytorch_mnist/mnist.ipynb#X51sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m plt\u001b[39m.\u001b[39mxlabel(\u001b[39m'\u001b[39m\u001b[39mnumber of training examples seen\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\jose\\anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\pyplot.py:2819\u001b[0m, in \u001b[0;36mscatter\u001b[1;34m(x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, edgecolors, plotnonfinite, data, **kwargs)\u001b[0m\n\u001b[0;32m   2814\u001b[0m \u001b[39m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[39m.\u001b[39mscatter)\n\u001b[0;32m   2815\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mscatter\u001b[39m(\n\u001b[0;32m   2816\u001b[0m         x, y, s\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, c\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, marker\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, cmap\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, norm\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   2817\u001b[0m         vmin\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, vmax\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, alpha\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, linewidths\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m,\n\u001b[0;32m   2818\u001b[0m         edgecolors\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, plotnonfinite\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, data\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m-> 2819\u001b[0m     __ret \u001b[39m=\u001b[39m gca()\u001b[39m.\u001b[39mscatter(\n\u001b[0;32m   2820\u001b[0m         x, y, s\u001b[39m=\u001b[39ms, c\u001b[39m=\u001b[39mc, marker\u001b[39m=\u001b[39mmarker, cmap\u001b[39m=\u001b[39mcmap, norm\u001b[39m=\u001b[39mnorm,\n\u001b[0;32m   2821\u001b[0m         vmin\u001b[39m=\u001b[39mvmin, vmax\u001b[39m=\u001b[39mvmax, alpha\u001b[39m=\u001b[39malpha, linewidths\u001b[39m=\u001b[39mlinewidths,\n\u001b[0;32m   2822\u001b[0m         edgecolors\u001b[39m=\u001b[39medgecolors, plotnonfinite\u001b[39m=\u001b[39mplotnonfinite,\n\u001b[0;32m   2823\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m({\u001b[39m\"\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\"\u001b[39m: data} \u001b[39mif\u001b[39;00m data \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m {}), \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   2824\u001b[0m     sci(__ret)\n\u001b[0;32m   2825\u001b[0m     \u001b[39mreturn\u001b[39;00m __ret\n",
      "File \u001b[1;32mc:\\Users\\jose\\anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\__init__.py:1412\u001b[0m, in \u001b[0;36m_preprocess_data.<locals>.inner\u001b[1;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1409\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[0;32m   1410\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minner\u001b[39m(ax, \u001b[39m*\u001b[39margs, data\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m   1411\u001b[0m     \u001b[39mif\u001b[39;00m data \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1412\u001b[0m         \u001b[39mreturn\u001b[39;00m func(ax, \u001b[39m*\u001b[39m\u001b[39mmap\u001b[39m(sanitize_sequence, args), \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1414\u001b[0m     bound \u001b[39m=\u001b[39m new_sig\u001b[39m.\u001b[39mbind(ax, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1415\u001b[0m     auto_label \u001b[39m=\u001b[39m (bound\u001b[39m.\u001b[39marguments\u001b[39m.\u001b[39mget(label_namer)\n\u001b[0;32m   1416\u001b[0m                   \u001b[39mor\u001b[39;00m bound\u001b[39m.\u001b[39mkwargs\u001b[39m.\u001b[39mget(label_namer))\n",
      "File \u001b[1;32mc:\\Users\\jose\\anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\axes\\_axes.py:4362\u001b[0m, in \u001b[0;36mAxes.scatter\u001b[1;34m(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, edgecolors, plotnonfinite, **kwargs)\u001b[0m\n\u001b[0;32m   4360\u001b[0m y \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mma\u001b[39m.\u001b[39mravel(y)\n\u001b[0;32m   4361\u001b[0m \u001b[39mif\u001b[39;00m x\u001b[39m.\u001b[39msize \u001b[39m!=\u001b[39m y\u001b[39m.\u001b[39msize:\n\u001b[1;32m-> 4362\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mx and y must be the same size\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   4364\u001b[0m \u001b[39mif\u001b[39;00m s \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   4365\u001b[0m     s \u001b[39m=\u001b[39m (\u001b[39m20\u001b[39m \u001b[39mif\u001b[39;00m rcParams[\u001b[39m'\u001b[39m\u001b[39m_internal.classic_mode\u001b[39m\u001b[39m'\u001b[39m] \u001b[39melse\u001b[39;00m\n\u001b[0;32m   4366\u001b[0m          rcParams[\u001b[39m'\u001b[39m\u001b[39mlines.markersize\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m \u001b[39m2.0\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: x and y must be the same size"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(train_counter, train_losses, color='blue')\n",
    "plt.scatter(test_counter, test_losses, color='red')\n",
    "plt.legend(['Train Loss', 'Test Loss'], loc='upper right')\n",
    "plt.xlabel('number of training examples seen')\n",
    "plt.ylabel('negative log likelihood loss')\n",
    "fig"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "10924a18004a67fec4ca520671884f363c8f96c2bbf22c2f0b2adbd21b6731df"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
